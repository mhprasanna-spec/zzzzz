
---

## ğŸŒ¸ LLaMA 3.2 Streamlit Chatbot (Ollama)

A simple **local AI chatbot** built using **Streamlit** and **Ollama**, powered by the `llama3.2:latest` model.
The app runs **fully offline** and includes a **floral background UI**.

---

## ğŸš€ Features

* ğŸ¦™ LLaMA 3.2 running locally via Ollama
* ğŸ’¬ Chat-style interface (Streamlit)
* âš¡ Streaming responses (real-time typing)
* ğŸŒ¸ Flower background with readable chat bubbles
* ğŸ”’ No API keys, no internet required

---

## ğŸ“ Project Structure

```
chatbot/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ flowers.jpg
â””â”€â”€ README.md
```

---

## ğŸ›  Prerequisites

* Python **3.9+**
* Ollama installed on your system

ğŸ‘‰ Download Ollama: [https://ollama.com](https://ollama.com)

---

## ğŸ“¦ Installation

### 1ï¸âƒ£ Create virtual environment (optional but recommended)

```bash
python -m venv venv
```

Activate it:

**Windows**

```bash
venv\Scripts\activate
```

**Mac / Linux**

```bash
source venv/bin/activate
```

---

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

### 3ï¸âƒ£ Pull the model

```bash
ollama pull llama3.2:latest
```

Make sure Ollama is running:

```bash
ollama run llama3.2:latest
```

---

## â–¶ Run the Application

```bash
streamlit run app.py
```

The app will open automatically in your browser.

---

## ğŸ¨ Customization

* Replace `flowers.jpg` with any background image
* Adjust CSS in `app.py` for colors, fonts, or layout
* Change model name if you use another Ollama model

---

## ğŸ§  Notes

* The `ollama` Python package is a **client only**
* Ollama must be running in the background
* Model downloads are handled by Ollama, not pip

---

## ğŸ™Œ Use Cases

* Local AI assistant
* Classroom demos
* Offline chatbot
* AI workshops and training sessions

---

## ğŸ“œ License

This project is for **learning and personal use**.
Feel free to modify and extend it.

---



Just tell me ğŸ˜Š
